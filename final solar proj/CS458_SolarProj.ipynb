{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41ncDfQIZ5gG"
   },
   "source": [
    "# **Solar Power Generation Forecast Report**\n",
    "\n",
    "Taylor Boyd\n",
    "\n",
    "CS458"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8goBinPaYnd"
   },
   "source": [
    "## **Part 1 - Splitting Data**\n",
    "\n",
    "**Split \"solar.csv\" into training dataset \"solar_training.csv\" and test dataset \"solar_test.csv\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4HJGE1w1aTqC"
   },
   "outputs": [],
   "source": [
    "f = open(\"solar.csv\", 'r')\n",
    "f2 = open(\"solar_training.csv\", 'w')\n",
    "f3 = open(\"solar_test.csv\", 'w')\n",
    "\n",
    "ctr = 0 # variable that tracks what line of the file we're on\n",
    "\n",
    "# go through each line of the file\n",
    "for line in f:\n",
    "    if ctr != 0:\n",
    "        a_str = line\n",
    "        a_str = a_str.strip().split(',')\n",
    "        time = a_str[1]\n",
    "        time = time.split(' ')\n",
    "        hr = time[1].split(\":\")\n",
    "        hr = int(hr[0])\n",
    "        # if timestamp is 20130701 00:00 or earlier, write data to training dataset file\n",
    "        if int(time[0]) < 20130701:\n",
    "            f2.write(line)\n",
    "        elif (int(time[0]) == 20130701 and hr == 0):\n",
    "            f2.write(line)\n",
    "        # else, write data to testing dataset file\n",
    "        else:\n",
    "            f3.write(line)\n",
    "    ctr +=1\n",
    "f.close()\n",
    "f2.close()\n",
    "f3.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onIeaqM3a_2C"
   },
   "source": [
    "In order to split the data, I casted the timestamp into different int parts. That way, it could be checked if the timestamp of any given line of data is smaller (earlier) or greater (later) than 20130701 00:00. If the timestamp was earlier than or equal to 20130701 00:00, the line of data is written to the training dataset file; otherwise, the line of data is written to the testing dataset file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8goBinPaYnd"
   },
   "source": [
    "## **Part 2 - Model Building**\n",
    "\n",
    "**Build a 24 hr ahead solar power generation forecast model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4HJGE1w1aTqC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "f2 = open(\"solar_training.csv\", 'r')\n",
    "f3 = open(\"solar_test.csv\", 'r')\n",
    "\n",
    "p1_trainingX = [] # plant 1 training data\n",
    "p1_trainingY = []\n",
    "p2_trainingX = [] # plant 2 training data\n",
    "p2_trainingY = []\n",
    "p3_trainingX = [] # plant 3 training data\n",
    "p3_trainingY = []\n",
    "\n",
    "p1_testX = [] # plant 1 test data\n",
    "p1_testY = []\n",
    "p2_testX = [] # plant 2 test data\n",
    "p2_testY = []\n",
    "p3_testX = [] # plant 3 test data\n",
    "p3_testY = []\n",
    "\n",
    "# helper function for separating data and labels\n",
    "def store_data(dataX, dataY, a_str):\n",
    "    a_str.pop(0)\n",
    "    a_str.pop(0)\n",
    "    temp = []\n",
    "    for item in range(len(a_str)-1):\n",
    "        temp.append(float(a_str[item]))\n",
    "    dataX.append(temp)\n",
    "    dataY.append(float(a_str[len(a_str)-1]))\n",
    "    return 0\n",
    "\n",
    "# go through each line of training dataset file\n",
    "for line in f2:\n",
    "    line = line.strip().split(',')\n",
    "    a_str = line\n",
    "    plant = int(a_str[0])\n",
    "    if plant == 1:\n",
    "        store_data(p1_trainingX, p1_trainingY, a_str)\n",
    "    elif plant == 2:\n",
    "        store_data(p2_trainingX, p2_trainingY, a_str)\n",
    "    else:\n",
    "        store_data(p3_trainingX, p3_trainingY, a_str)\n",
    "        \n",
    "# go through each line of testing dataset file\n",
    "for line in f3:\n",
    "    line = line.strip().split(',')\n",
    "    a_str = line\n",
    "    plant = int(a_str[0])\n",
    "    if plant == 1:\n",
    "        store_data(p1_testX, p1_testY, a_str)\n",
    "    elif plant == 2:\n",
    "        store_data(p2_testX, p2_testY, a_str)\n",
    "    else:\n",
    "        store_data(p3_testX, p3_testY, a_str)\n",
    "        \n",
    "f2.close()\n",
    "f3.close()\n",
    "\n",
    "# convert lists to np arrays\n",
    "p1_trainingX = np.array(p1_trainingX)\n",
    "p1_trainingY = np.array(p1_trainingY)\n",
    "p2_trainingX = np.array(p2_trainingX)\n",
    "p2_trainingY = np.array(p2_trainingY)\n",
    "p3_trainingX = np.array(p3_trainingX)\n",
    "p3_trainingY = np.array(p3_trainingY)\n",
    "p1_testX = np.array(p1_testX)\n",
    "p1_testY = np.array(p1_testY)\n",
    "p2_testX = np.array(p2_testX)\n",
    "p2_testY = np.array(p2_testY)\n",
    "p3_testX = np.array(p3_testX)\n",
    "p3_testY = np.array(p3_testY)\n",
    "\n",
    "# function that splits labels into 5 different classes\n",
    "def split_classes(arr):\n",
    "    new_arr = np.zeros(arr.shape[0])\n",
    "    for i in range(arr.shape[0]):\n",
    "        if arr[i] < 0.2:\n",
    "            new_arr[i] = 0\n",
    "        elif arr[i] < 0.4:\n",
    "            new_arr[i] = 1\n",
    "        elif arr[i] < 0.6:\n",
    "            new_arr[i] = 2\n",
    "        elif arr[i] < 0.8:\n",
    "            new_arr[i] = 3\n",
    "        else:\n",
    "            new_arr[i] = 4\n",
    "    return new_arr\n",
    "\n",
    "# variables for newly defined labels\n",
    "p1train = np.array(split_classes(p1_trainingY))\n",
    "p2train = np.array(split_classes(p2_trainingY))\n",
    "p3train = np.array(split_classes(p3_trainingY))\n",
    " \n",
    "# build svr classifier for each plant\n",
    "regr1 = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
    "regr1.fit(p1_trainingX, p1train)\n",
    "regr2 = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
    "regr2.fit(p2_trainingX, p2train)\n",
    "regr3 = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
    "regr3.fit(p3_trainingX, p3train)\n",
    "\n",
    "# function for predicting power generation 24hrs after givin timestamp\n",
    "# takes in n which is the index for the sample with targeted timestamp\n",
    "def predict_tmrw(clf, testX, n):\n",
    "    window = []\n",
    "    # if there is a week of history, use that to make prediction\n",
    "    for i in range(7):\n",
    "        if (n-i) >= 0:\n",
    "            window.append(testX[n-i])\n",
    "    window = np.array(window)\n",
    "    pred = 0\n",
    "    preds = 0\n",
    "    for i in range(window.shape[0]):\n",
    "        preds += clf.predict(window)\n",
    "    for i in range(preds.size):\n",
    "        pred += preds[i]\n",
    "    pred = pred / preds.size\n",
    "    pred = (pred / window.shape[0]) / 5 + 0.1\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onIeaqM3a_2C"
   },
   "source": [
    "In order to build classifiers for each solar plant and make 24hr window predictions, I first decided to split the possible power generation into 5 different ranges (0-0.2, 0.2-0.4, 0.4-0.6, 0.6-0.8, 0.8-1.0). Using the newly defined training labels, I built a classifier for each solar plant. Next, I made a function that makes the predictions for 24hrs ahead. It takes in a classifier, test samples, and some index and basically looks at the last week of data (if it's available) in order to make the prediction. The power generation predictions from the last 7 days are averaged in order to come up with the 24hr prediction as output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vusqyELcnd5"
   },
   "source": [
    "## **Part 3 - Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbKeiSBCcx64"
   },
   "source": [
    "**Use MAE and RMSE measures to evaluate the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "4HJGE1w1aTqC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE\n",
      "0.1781144352180035\n",
      "0.1871333440553051\n",
      "0.18999626716860712\n",
      "RMSE\n",
      "0.22121105569287766\n",
      "0.23172321897512396\n",
      "0.23444825402235855\n"
     ]
    }
   ],
   "source": [
    "# takes in trained model and test data, outputs mae\n",
    "def mae_function(model, testX, testY):\n",
    "    mae = 0\n",
    "    for i in range(testX.shape[0]):\n",
    "        pred = predict_tmrw(model, testX, i)\n",
    "        mae += abs(testY[i] - pred)\n",
    "    mae = mae / testX.shape[0]\n",
    "    return mae\n",
    "\n",
    "# takes in trained model and test data, outputs rmse\n",
    "def rmse_function(model, testX, testY):\n",
    "    rmse = 0\n",
    "    for i in range(testX.shape[0]):\n",
    "        pred = predict_tmrw(model, testX, i)\n",
    "        rmse += (abs(testY[i] - pred)) * (abs(testY[i] - pred))\n",
    "    rmse = rmse / testX.shape[0]\n",
    "    rmse = math.sqrt(rmse)\n",
    "    return rmse\n",
    "\n",
    "# calculate and print mae of each plant's model\n",
    "p1_mae = mae_function(regr1, p1_testX, p1_testY)\n",
    "p2_mae = mae_function(regr2, p2_testX, p2_testY)\n",
    "p3_mae = mae_function(regr3, p3_testX, p3_testY)\n",
    "print(\"MAE\")\n",
    "print(p1_mae)\n",
    "print(p2_mae)\n",
    "print(p3_mae)\n",
    "\n",
    "# calculate and print rmse of each plant's model\n",
    "p1_rmse = rmse_function(regr1, p1_testX, p1_testY)\n",
    "p2_rmse = rmse_function(regr2, p2_testX, p2_testY)\n",
    "p3_rmse = rmse_function(regr3, p3_testX, p3_testY)\n",
    "print(\"RMSE\")\n",
    "print(p1_rmse)\n",
    "print(p2_rmse)\n",
    "print(p3_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onIeaqM3a_2C"
   },
   "source": [
    "RMSE results are a little worse than MAE results but both are pretty good overall. I think it's interesting that the error is higher for plant 3 predictions in both calculations."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ProjectTemplate.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
